---
title: "The best way to learn about AI Agents"
date: 2024-12-18
categories: [AI]
tags: [AI,Machine learning,GPT]
description: "The best way to learn about AI Agents is to understand their evolution, here's how to approach it better..."
---
The best way to learn about AI Agents is to understand their evolution, here's how to approach it better...
From the rise of Generative AI technology like LLMs,<br/>
There's been a desire for a well-equipped autonomous system that could use a wide range of tools yet be very conversational.
They could utilize the very foundation of GenAI and include other cognitive features like Memory,<br/>
So, after several iterations, we finally came down to Agents but it was not a straightforward change,<br/>
ðŸ“Œ here are a few iterations made along the way to where we are as an Agentic system:<br/>
1. The Very Beginning - A Large Language Model<br/>
- Workflow: Input: Text â†’ LLM â†’ Output: Text<br/>
- These are the transformer-based architectures that were trained on a large variation of datasets to create intelligent chatbots.<br/>
- This laid the very foundation of AI Agent's future.<br/>
2. LLM with larger context Inputs and Outputs:<br/>
- Workflow: Input: Text/Document â†’ LLM â†’ Output: Text/Document<br/>
- With LLMs became smarter so they needed to process information beyond the 8k context window.<br/>
- The new LLM architecture was updated with a larger context window to parse bigger documents.<br/>
3. RAGs and Tool use<br/>
- Workflow Input: Text/Document corpus â†’ LLM + Tool use + RAGs â†’ Output: Text/Document<br/>
- Access to the latest information soon became the new trend in GenAI. Hence, RAGs were introduced.<br/>
- Similar to RAGs, to improve LLMs responses we started seeing more tool integrations like search API to improve results.<br/>
4. Introduction to Multi-Modal workflow<br/>
- Workflow: Multi-Modal Input â†’ LLM + Tool use + RAGs â†’ Multi-modal Output<br/>
- This laid the very foundation of a simple agentic architecture.<br/>
- With the support of real-time data retrieval features, these agents can already perform complex tasks with decent human intervention.<br/>
4. Our current AI Agent architecture<br/>
- Workflow: Text + Multi-Modal Data Input â†’ LLM + Tool Use + Memory â†’ Decision â†’ Text + Multi-Modal Data Output<br/>
- AI agents are now equipped with advanced structures:<br/>
 a. Memory types: Short-term, Long-term and Episodic to remember past activities for improvements.<br/>
 b. Tool Calling: Utilizing third-party APIs for performing a wide range of tasks like search, flight booking, etc.<br/>
 c. Decision: Rather than just failing to act, it uses ReACT to start the process again with a different approach to get an output.<br/>
 d. Supporting better Knowledge bases: Current agents now utilise even semantic databases to form better connections across different nodes for improved reasoning.<br/>
5. Future architecture of AI Agents
<br/>
What are your views on the future of AI Agents?<br/>

<b>Link</b> :https://www.facebook.com/share/p/1CsXRDVFPX/

<img src="https://scontent.fdad1-4.fna.fbcdn.net/v/t39.30808-6/470601703_2863041753855534_236101963265846964_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=aa7b47&_nc_eui2=AeGyuUGyeu-F-6HBY7chkwjnWRmBbrcz50ZZGYFutzPnRqPrb-c7KSyF7A2-pQZukMFwdMfUUdxOWK9W-8VfcQIO&_nc_ohc=pcUvzohtb0MQ7kNvgEyWwbY&_nc_oc=AdiQ3qGP3sn2AfWsBU5WwkLI_A9ck_yyYPXGQ6KjsZ4oqlErncelt5wlS4L2JzDMK98&_nc_zt=23&_nc_ht=scontent.fdad1-4.fna&_nc_gid=Au2JsMBpxhq1VGVHwD4p5h7&oh=00_AYC8vk7hsAqkUG7K-mf2kOJUFE3EN4VLDfUcUp5NLUt02Q&oe=676CC823"/>
